{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear Regression is one of the simplest, oldest and more used\n",
    "methods of data analysis and in many cases is the starting point\n",
    "when we try to derive a model by fitting a straight line to data.\n",
    "\n",
    "In its simplest version we have one independent and one depended\n",
    "variables and we are trying to a find a **linear** relationship\n",
    "between them that will allow us to make predictions based on unseen\n",
    "before values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_dummy_data(func, x1=0, x2=100, count=10, mu=0, sigma=65):\n",
    "    \"\"\"Creates testing data to use for simple Linear Regression.\n",
    "    \n",
    "    :param callable func: A linear function that maps the x value \n",
    "    to a y; resembles the y = ax + b functionality.\n",
    "    \n",
    "    :param float x1: The min x for the data set to return.\n",
    "    :param float x2: The max y for the data set to return.\n",
    "    :param int count: The number of the points to return.\n",
    "    :param float mu: The mean value of the residual distribution.\n",
    "    :param float sigma: The sigma value of the residual distribution.\n",
    "    \n",
    "    :returns: A tuple consisting of the x and y values that correspond\n",
    "    to the passed in parameters.\n",
    "    \n",
    "    :rtype: tuple[list, list]\n",
    "    \"\"\"\n",
    "    x_values = np.random.uniform(low=x1, high=x2, size=(count,))\n",
    "    noise = np.random.normal(mu, sigma, count)\n",
    "    y_values = []\n",
    "    for index, x in enumerate(x_values):\n",
    "        y = func(x)\n",
    "        noisy_value = y + noise[index]\n",
    "        y_values.append(noisy_value)\n",
    "    return x_values, y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Developing intuition for a single-variabled linear model\n",
    "\n",
    "Using the function to make dummy data, we can simulate a random population\n",
    "of points expressed as tuples $(x,y)$ that can mimic some data that we have\n",
    "collected for a specific experiment.\n",
    "\n",
    "In our case, we now in advance the function that is combining the dependent with\n",
    "the independent variable which can be expressed in a linear format as follows:\n",
    "\n",
    "$\\Large y = a \\cdot x + b$\n",
    "\n",
    "Note that the dummy point generator is adding some random noise (normally distributed)\n",
    "to make our case study more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "func = lambda x: 5 + 2.8 * x\n",
    "x_values, y_values = make_dummy_data(func=func, x1=0, x2=10 , sigma=8, count=8)\n",
    "\n",
    "max_x = int(max(x_values)) + 2\n",
    "max_y = int(max(y_values)) + 2\n",
    "\n",
    "plt.scatter(x_values, y_values, color=\"red\")\n",
    "\n",
    "# Pick a random line.\n",
    "func_1 = lambda x: 2.6 + 2.0 * x\n",
    "y_1 = [func_1(x) for x in x_values ]\n",
    "plt.plot(x_values, y_1, color='blue', linewidth=3.1)\n",
    "\n",
    "# Print the distances from the points\n",
    "delta_y = []\n",
    "for index in range(len(x_values)):\n",
    "    x = x_values[index]\n",
    "    plt.plot([x,  x] , [y_values[index], func_1(x)] , color='green', linestyle='dashed',)\n",
    "    delta_y.append((x, y_values[index] - func_1(x)))\n",
    "    \n",
    "plt.plot([x for x in range(0, max_x)], [0 for x in range(0, max_x)], color=\"black\", linewidth = 3.1)\n",
    "plt.plot([0 for x in range(0, max_y)], [y for y in range(0, max_y)], color=\"black\", linewidth = 3.1)\n",
    "\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "delta_y.sort(key= lambda p: p[0])\n",
    "df = pd.DataFrame(delta_y, columns = ['x', 'ΔY'])\n",
    "df['ΔY^2'] = df.apply(lambda row: row[\"ΔY\"]**2, axis=1)\n",
    "squares_sum =  df['ΔY'].sum()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The \"blue\" line that we have ploted above is a randomnly selected one having \n",
    "arbitrary values for its **slope** ($a$) and **intercept** ($b$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How to find the best values for a and b\n",
    "\n",
    "From the 3-d graphical represenation that follows we can see how the observed error\n",
    "varies based on the values of $a$ and $b$.\n",
    "\n",
    "Our objective is to find out the values of both $a$ and $b$ that minimize the error.\n",
    "It is easy to realize that since the error function is monotonous, we need to find\n",
    "the values that make the derivates of them equal to zero, or expresssed more \n",
    "formally the following:\n",
    "\n",
    "$\\Large \\frac {\\partial C} {\\partial a} = 0$\n",
    "\n",
    "$\\Large \\frac {\\partial C} {\\partial b} = 0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "func = lambda x:3.2*x  + 2.2\n",
    "x_values, y_values = make_dummy_data(func=func,  x1=0, x2=50, mu=0, sigma=55,  count=1000)\n",
    "zis, yis, xis = [], [], []\n",
    "\n",
    "step = .05\n",
    "for a in np.arange(2, 4, step):\n",
    "    for b in np.arange(1.5, 2.2, step):\n",
    "        xis.append(a)\n",
    "        yis.append(b)\n",
    "        s = 0\n",
    "        for x, y in zip(x_values, y_values):\n",
    "            s += (a * x + b - y) **2\n",
    "        zis.append( s) \n",
    "fig = plt.figure(figsize=(8, 6), dpi=80)\n",
    "ax = plt.axes(projection ='3d')\n",
    "ax.scatter(xis, yis, zis, 'blue')\n",
    "ax.set_title('Cost Function where a and b are the input.')\n",
    "ax.set_zticks([min(zis), max(zis)])\n",
    "ax.set_xlabel(r'a', fontsize=30, rotation=0, color=\"gray\")\n",
    "ax.set_ylabel(r'b', fontsize=30, rotation=0, color=\"gray\")\n",
    "ax.set_zlabel(r'Error', fontsize=30, rotation=60, color=\"gray\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the picture about we can visually understand why we need the partial \n",
    "derivatives of $a$ and $b$ to become zero in order to minimize the total \n",
    "error (also known as cost).  The necessary math are the following:\n",
    "\n",
    "<img src=\"./images/solving-least-squares.png\" style=\"float:left\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Least Squares Regression Line\n",
    "\n",
    "The mathematical method to identify the best possible values for\n",
    "$a$ (**slope**) and $b$ (**y-intercept**)  is called **Least Squares\n",
    "Regression Line**\n",
    "\n",
    "An informal definition of the **Least Squares Line** is that it is the line\n",
    "that given a set of points in the plane it minimizes the sum of distances\n",
    "from them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def solve_linear_regression(x, y):\n",
    "    \"\"\"Finds the Least Square line.\n",
    "    \n",
    "    In real world we do not need to implement this function\n",
    "    from scratch, sklearn linear model should be used instead.\n",
    "    \n",
    "    :param np.array | list x: The independed values.\n",
    "    :param np.array | list y: The depended values.\n",
    "    \n",
    "    :returns: The linear function that will make predictions \n",
    "    for the passed in x value.\n",
    "    \n",
    "    :rtype: callable.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x = np.array(x)\n",
    "        \n",
    "    if isinstance(y, list):\n",
    "        y = np.array(y)\n",
    "        \n",
    "    assert x.size == y.size\n",
    "    \n",
    "    n = x.size\n",
    "    A = np.sum(np.square(x))\n",
    "    B = np.sum(x)\n",
    "    C = np.sum(x*y)\n",
    "    D = np.sum(y)\n",
    "    \n",
    "    assert B**2 - A* n != 0\n",
    "    assert B != 0\n",
    "    \n",
    "    b = (C * B - A * D) / (B**2 - A* n)\n",
    "    a = (D - n * b) / B\n",
    "    \n",
    "    \n",
    "    return lambda x: a*x +b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "func = lambda x:3.2 * x + 20\n",
    "x_values, y_values = make_dummy_data(func=func,  x1=0, x2=50, mu=0, sigma=10,  count=100)\n",
    "_ = plt.scatter(x_values, y_values, color=\"red\")\n",
    "least_squares_line =  solve_linear_regression(x_values, y_values)\n",
    "_ = plt.plot(x_values, func(x_values), color='g')\n",
    "_ = plt.plot(x_values, least_squares_line(x_values), color='b')\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([ \"Obvervations\",  'Expected line', 'Least Squares Line'])\n",
    "_ = plt.title(\"Example of how the least squares line looks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate Least Square line using SkLearn\n",
    "\n",
    "In real world we are not hand craft solutions to the linear regression problem as we did here; instead we use third party \n",
    "libraries that are well tested and highly optimized.\n",
    "\n",
    "In python world the most commonly used library is sklearn linear model as can be see in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit([list(x_values)], [list(y_values)])\n",
    "x = np.array(x_values).reshape(100,1)\n",
    "y = np.array(y_values).reshape(100,1)\n",
    "model  = LinearRegression().fit(x, y)\n",
    "_ = plt.scatter(x_values, y_values, color=\"red\")\n",
    "b = model.intercept_[0]\n",
    "a = model.coef_[0][0]\n",
    "func = lambda x:x * a + b\n",
    "_ = plt.plot(x_values, func(x_values), color='b')\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([ \"Obvervations\",  'Least Squares Line'])\n",
    "_ = plt.title(\"Least squares line using sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Closed Solution \n",
    "\n",
    "The solution we have given above to the problem of Linear Regression is called a **closed formula** meaning that we can apply an single function and calculate the line. \n",
    "\n",
    "We will see another way that we can follow fo solve the least squares which will contain all the steps (albeit simpler) that we will use in many other methods on machine learning. \n",
    "\n",
    "\n",
    "### The  four assumptions of applying a linear regression model\n",
    "\n",
    "To apply the Least Squares solution to a set of data they need to meet several assumptions otherwise the results will not be accurate.  \n",
    "\n",
    "These assumptions can be summarized as follows:\n",
    "\n",
    "\n",
    "| Name      | Description |\n",
    "| ----------- | ----------- |\n",
    "| Linearity      | The relationship between X and the mean of Y is linear       |\n",
    "| Homoscedasticity   | The variance of residual is the same for any value of X |\n",
    "|Independence |Observations are independent of each other.|\n",
    "|Normality|For any fixed value of X, Y is normally distributed.|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit([list(x_values)], [list(y_values)])\n",
    "x = np.array(x_values).reshape(100,1)\n",
    "y = np.array(y_values).reshape(100,1)\n",
    "model  = LinearRegression().fit(x, y)\n",
    "_ = plt.scatter(x_values, y_values, color=\"red\")\n",
    "b = model.intercept_[0]\n",
    "a = model.coef_[0][0]\n",
    "func = lambda x:x * a + b\n",
    "_ = plt.plot(x_values, func(x_values), color='b')\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([ \"Obvervations\",  'Least Squares Line'])\n",
    "_ = plt.title(\"Least squares line using sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Closed Solution \n",
    "\n",
    "The solution we have given above to the problem of Linear Regression is called a **closed formula** meaning that we can apply an single function and calculate the line. \n",
    "\n",
    "We will see another way that we can follow fo solve the least squares which will contain all the steps (albeit simpler) that we will use in many other methods on machine learning. \n",
    "\n",
    "\n",
    "### The  four assumptions of applying a linear regression model\n",
    "\n",
    "To apply the Least Squares solution to a set of data they need to meet several assumptions otherwise the results will not be accurate.  \n",
    "\n",
    "These assumptions can be summarized as follows:\n",
    "\n",
    "\n",
    "| Name      | Description |\n",
    "| ----------- | ----------- |\n",
    "| Linearity      | The relationship between X and the mean of Y is linear       |\n",
    "| Homoscedasticity   | The variance of residual is the same for any value of X |\n",
    "|Independence |Observations are independent of each other.|\n",
    "|Normality|For any fixed value of X, Y is normally distributed.|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit([list(x_values)], [list(y_values)])\n",
    "x = np.array(x_values).reshape(100,1)\n",
    "y = np.array(y_values).reshape(100,1)\n",
    "model  = LinearRegression().fit(x, y)\n",
    "_ = plt.scatter(x_values, y_values, color=\"red\")\n",
    "b = model.intercept_[0]\n",
    "a = model.coef_[0][0]\n",
    "func = lambda x:x * a + b\n",
    "_ = plt.plot(x_values, func(x_values), color='b')\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([ \"Obvervations\",  'Least Squares Line'])\n",
    "_ = plt.title(\"Least squares line using sklearn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Closed Solution \n",
    "\n",
    "The solution we have given above to the problem of Linear Regression is called a **closed formula** meaning that we can apply an single function and calculate the line. \n",
    "\n",
    "We will see another way that we can follow fo solve the least squares which will contain all the steps (albeit simpler) that we will use in many other methods on machine learning. \n",
    "\n",
    "\n",
    "### The  four assumptions of applying a linear regression model\n",
    "\n",
    "To apply the Least Squares solution to a set of data they need to meet several assumptions otherwise the results will not be accurate.  \n",
    "\n",
    "These assumptions can be summarized as follows:\n",
    "\n",
    "\n",
    "| Name      | Description |\n",
    "| ----------- | ----------- |\n",
    "| Linearity      | The relationship between X and the mean of Y is linear       |\n",
    "| Homoscedasticity   | The variance of residual is the same for any value of X |\n",
    "|Independence |Observations are independent of each other.|\n",
    "|Normality|For any fixed value of X, Y is normally distributed.|\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}